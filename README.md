# ETL - SQL

En este repositorio fue creado con el prop칩sito de aprender acerca de pipeline en ambitos aplicados, partiendo de la idea de la transformaci칩n y el guardado de csv o excel a base de datos sql que podran ser consultados y tratados para **reportes o BI**.

##  Objetivos de aprendizaje
- Practicar consultas SQL b치sicas (SELECT, WHERE, ORDER BY, LIMIT, etc.).
- Integrar Python con PostgreSQL para construir un pipeline ETL.
- Preparar la base para an치lisis y visualizaci칩n de datos.
- Aprender buenas pr치cticas de versionado y organizaci칩n de proyectos.


## Estructura del proyecto

datasets/
etl/
sql/
exports/ "se a침adir치 mas tarde"

## 游댢 Requisitos
- Python 3.10+  
- PostgreSQL 14+  
- DBeaver (cliente gr치fico para SQL)  
- VS Code (editor recomendado)  

---

## 郊윒잺 Uso b치sico
1. Crear la base de datos `school_db` en PostgreSQL.  
2. Importar dataset de ejemplo (`datasets/students.csv`).  
3. Ejecutar las consultas de `sql/01-select-queries.sql` en DBeaver.  
4. (M치s adelante) correr scripts de `/etl` para automatizar el pipeline.

---

## 游닄 Avances
- **D칤a 1**: Setup de proyecto, importaci칩n de dataset y primeras consultas SQL.  
  - SELECT, WHERE, ORDER BY, LIMIT.  
  - Primer commit del repo.

---

## 游늷 Pr칩ximos pasos
- A침adir m치s consultas SQL (JOIN, GROUP BY, agregaciones).  
- Crear primer script ETL en Python (`etl/pipeline.py`).  
- Configurar exportaciones en `/exports`.
