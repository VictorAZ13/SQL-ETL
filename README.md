# ETL - SQL

En este repositorio fue creado con el prop칩sito de aprender acerca de pipeline en ambitos aplicados, partiendo de la idea de la transformaci칩n y el guardado de csv o excel a base de datos sql que podran ser consultados y tratados para **reportes o BI**.

##  Objetivos de aprendizaje
- Practicar consultas SQL b치sicas (SELECT, WHERE, ORDER BY, LIMIT, etc.).
- Integrar Python con PostgreSQL para construir un pipeline ETL.
- Preparar la base para an치lisis y visualizaci칩n de datos.
- Aprender buenas pr치cticas de versionado y organizaci칩n de proyectos.


## Estructura del proyecto

datasets/
etl/
sql/
exports/ "se a침adir치 mas tarde"

## 游댢 Requisitos
- Python 3.10+  
- PostgreSQL 14+  
- DBeaver (cliente gr치fico para SQL)  
- VS Code (editor recomendado)  

---

## 郊윒잺 Uso b치sico
1. Crear la base de datos `school_db` en PostgreSQL.  
2. Importar dataset de ejemplo (`datasets/students.csv`).  
3. Ejecutar las consultas de `sql/01-select-queries.sql` en DBeaver.  
4. (M치s adelante) correr scripts de `/etl` para automatizar el pipeline.

---

## 游닄 Avances
- **D칤a 1**: Setup de proyecto, importaci칩n de dataset y primeras consultas SQL.  
  - SELECT, WHERE, ORDER BY, LIMIT.  
  - Primer commit del repo.
- **D칤a 2**: Funciones de agregaci칩n y agrupaci칩n (SQL)
  - Practiqu칠 funciones de agregaci칩n: `COUNT`, `MIN`, `MAX`, `AVG`, `SUM`.
  - Aprend칤 a usar `GROUP BY` para resumir datos categ칩ricos (g칠nero, curso, departamento).
  - Us칠 `HAVING` para filtrar resultados despu칠s de agrupar.
  - Combin칠 `GROUP BY + HAVING + ORDER BY` para generar rankings (ej. curso con m치s alumnos, departamento con mejor promedio).
  - Reto resuelto: encontrar el departamento con mejor promedio de calificaci칩n entre los que tienen m치s de 8 alumnos.
---

## 游늷 Pr칩ximos pasos
- A침adir m치s consultas SQL (JOIN, GROUP BY, agregaciones).  
- Crear primer script ETL en Python (`etl/pipeline.py`).  
- Configurar exportaciones en `/exports`.
